---
title: 隐性语义索引（Latent Semantic Indexing）
date: 2017-04-12 10:33:12
categories: ml
tags:
 - nlp
 - lsi
---

隐性语义索引(LSI)采用线性代数中的奇异值分解方法，选取前几个比较大的奇异值所对应的特征向量将原矩阵映射到低维空间中，从而达到词矢量的目的。

<!-- more -->

# 奇异矩阵分解SVD

奇异矩阵分解SVD的内容见[上文博客](/2017/04/12/%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3-SVD/)。

# 词项—文档矩阵及SVD

词项-文档矩阵是一个由$M$个词项和$N$篇文档组成的$M×N$的权重矩阵$C$，矩阵的每行代表一个词项，每列代表一篇文档。然而，我们感兴趣的是$M×N$的词项—文档矩阵$C$，一般有$M\neq N$。这个矩阵经过SVD分解之后的形势如下式所示：

$$\begin{equation}
CC^T =UΣV^TVΣ^TU^T =UΣΣ^TU^T
\end{equation}$$

那么左边的$CC^T$ 代表什么呢？它实际上是一个方阵，其每行和每列都对应$M$个词项中的一个。矩阵中的第$i$行、第$j$列的元素实际上是第$i$个词项与第$j$个词项基于文档共现次数的一个重合度计算指标（可以从矩阵的乘法中推断出来）。其精确的数学含义依赖于构建$C$所使用的词项权重方法。假定$C$是词项-文档出现矩阵，那么$CC^T$的第$i$行、第$j$列的元素是词项$i$和词项$j$共现的文档数目。

# 低秩逼近

小特征值对于矩阵乘法的影响也小。因此，将这些小特征值替换成0将不会对最后的乘积有实质性影响，也就是说该乘积接近$C$。SVD可以用于解决矩阵低秩逼近问题，主要操作分为以下三步：

1. 给定$C$，构造SVD分解有$C = UΣV^T$；
2. 把$Σ$中对角线上$r-k$个最小奇异值置为0，从而得到$Σ_k$；
3. 计算$C_k = UΣ_kV^T$作为$C$的逼近。

# 潜在语义索引LSI

空间向量模型可以将查询和文档转换成同一空间下的向量，可以基于余弦相似度进行评分计算，能够对不同的词项赋予不同的权重，除了文档检索之外还可以推广到诸如聚类和分类等其他领域，等等。但是，向量空间表示方法没有能力处理自然语言中的两个经典问题：一义多词（synonymy）和一词多义（polysemy）问题。一个很自然的问题就是，能否利用词项的共现情况（比如，charge是和steed 还是electron在某篇文档中共现），来获得词项的隐性语义关联从而减轻这些问题的影响？

即使对一个中等规模的文档集来说，词项-文档矩阵$C$也可能有成千上万个行和列，它的秩数目大概也是这个数量级。在LSI中，我们使用SVD分解来构造$C$的一个低秩逼近$C_k$，其中$k$远小于矩阵$C$原始的秩。实践时$k$的取值往往在几百以内。这样，我们就可以将词项—文档矩阵中每行和每列（分别对应每个词项和每篇文档）映射到一个$k$维空间，为$CC^T$和$C^TC$的$k$个主特征向量（对应$k$个最大的特征值）可以定义该空间。需要注意的是，不管$k$取值如何，矩阵$C_k$仍然是一个$M × N$的矩阵。矩阵$U$被称为SVD词项矩阵（SVD term matrix）,$V^T$被称为SVD文档矩阵（SVD document matrix）。

# 举例

考虑如下词项—文档矩阵 C =


| | $d_1$ | $d_2$ | $d_3$ | $d_4$ | $d_5$ | $d_6$ |
|-|-------|-------|-------|-------|-------|
| ship | 1 | 0 | 1 | 0 | 0 | 0 |
| boat | 0 | 1 | 0 | 0 | 0 | 0 |
| ocean | 1 | 1 | 0 | 0 | 0 | 0 |
| voyage | 1 | 0 | 0 | 1 | 1 | 0 |
| trip | 0 | 0 | 0 | 1 | 0 | 1 |

利用SVD分解，可以将其分解生成三个矩阵的乘积。

计算$CC^T$的值为

$$\begin{eqnarray}
CC^T=
\begin{pmatrix}
1  &  0  &  1  &  0  &  0  &  0 \\\\
0  &  1  &  0  &  0  &  0  &  0 \\\\
1  &  1  &  0  &  0  &  0  &  0 \\\\
1  &  0  &  0  &  1  &  1  &  0 \\\\
0 & 0 & 0 & 1 & 0 & 1
\end{pmatrix}
\begin{pmatrix}
1  &  0  &  1  &  1  &  0 \\\\
0  &  1  &  1  &  0  &  0 \\\\
1  &  0  &  0  &  0  &  0 \\\\
0  &  0  &  0  &  1  &  1 \\\\
0  &  0  &  0  &  1  &  0 \\\\
0 & 0 & 0 & 0 & 1
\end{pmatrix}
=
\begin{pmatrix}
2  &  0  &  1  &  1  &  0 \\\\
0  &  1  &  1  &  0  &  0 \\\\
1  &  1  &  2  &  1  &  0 \\\\
1  &  0  &  1  &  3  &  1 \\\\
0 & 0 & 0 & 1 & 2
\end{pmatrix}
\end{eqnarray}$$

$CC^T$对应的特征值和特征向量为：

$$\begin{equation}
\lambda_1=4.68,p_1=\begin{pmatrix} 0.44  &  0.13  &  0.48  &  0.70  &  0.26 \end{pmatrix}^T\\\\
\lambda_2=2.54,p_2=\begin{pmatrix} 0.30  &  0.33  &  0.51  &  -0.35  &  -0.65 \end{pmatrix}^T\\\\
\lambda_3=1.63,p_3=\begin{pmatrix} 0.57  &  -0.59  &  -0.37  &  0.15  &  -0.41 \end{pmatrix}^T\\\\
\lambda_4=1,p_4=\begin{pmatrix} 0.58  &  -0.00  &  -0.00  &  -0.58  &  0.58 \end{pmatrix}^T\\\\
\lambda_5=0.16,p_5=\begin{pmatrix} -0.25  &  -0.73  &  0.61  &  -0.16  &  0.09 \end{pmatrix}^T
\end{equation}$$

计算$C^TC$的值为
$$\begin{eqnarray}
C^TC=
\begin{pmatrix}
1  &  0  &  1  &  1  &  0 \\\\
0  &  1  &  1  &  0  &  0 \\\\
1  &  0  &  0  &  0  &  0 \\\\
0  &  0  &  0  &  1  &  1 \\\\
0  &  0  &  0  &  1  &  0 \\\\
0 & 0 & 0 & 0 & 1
\end{pmatrix}
\begin{pmatrix}
1  &  0  &  1  &  0  &  0  &  0 \\\\
0  &  1  &  0  &  0  &  0  &  0 \\\\
1  &  1  &  0  &  0  &  0  &  0 \\\\
1  &  0  &  0  &  1  &  1  &  0 \\\\
0 & 0 & 0 & 1 & 0 & 1
\end{pmatrix}
=
\begin{pmatrix}
3  &  1  &  1  &  1  &  1  &  0 \\\\
1  &  2  &  0  &  0  &  0  &  0 \\\\
1  &  0  &  1  &  0  &  0  &  0 \\\\
1  &  0  &  0  &  2  &  1  &  1 \\\\
1  &  0  &  0  &  1  &  1  &  0 \\\\
0 & 0 & 0 & 1 & 0 & 1
\end{pmatrix}
\end{eqnarray}$$

$C^TC$对应的特征值和特征向量为：

$$\begin{equation}
\lambda_1=4.68,p_1=\begin{pmatrix} -0.75  &  -0.28  &  -0.20  &  -0.45  &  -0.33  &  -0.12 \end{pmatrix}^T\\\\
\lambda_2=2.54,p_2=\begin{pmatrix} -0.29  &  -0.53  &  -0.19  &  0.63  &  0.22  &  0.41 \end{pmatrix}^T\\\\
\lambda_3=1.63,p_3=\begin{pmatrix} -0.28  &  0.75  &  -0.45  &  0.20  &  -0.12  &  0.33 \end{pmatrix}^T\\\\
\lambda_4=1,p_4=\begin{pmatrix} 0.00  &  -0.00  &  0.58  &  -0.00  &  -0.58  &  0.58 \end{pmatrix}^T\\\\
\lambda_5=0.16,p_5=\begin{pmatrix} 0.53  &  -0.29  &  -0.63  &  -0.19  &  -0.41  &  0.22 \end{pmatrix}^T\\\\
\lambda_6=0.16,p_6=\begin{pmatrix} 0.00  &  -0.00  &  -0.00  &  -0.58  &  0.58  &  0.58 \end{pmatrix}^T
\end{equation}$$

则根据以上SVD分解有：

$$\begin{eqnarray}
C&=&UΣV^T=
\begin{pmatrix}
1 & 0 & 1 & 0 & 0 & 0 \\\\
0 & 1 & 0 & 0 & 0 & 0 \\\\
1 & 1 & 0 & 0 & 0 & 0 \\\\
1 & 0 & 0 & 1 & 1 & 0 \\\\
0 & 0 & 0 & 1 & 0 & 1
\end{pmatrix}\\\\
&=&
\begin{pmatrix}
0.44 & 0.30 & 0.57 & 0.58 & -0.25 \\\\
0.13 & 0.33 & -0.59 & -0.00 & -0.73 \\\\
0.48 & 0.51 & -0.37 & -0.00 & 0.61 \\\\
0.70 & -0.35 & 0.15 & -0.58 & -0.16 \\\\
0.26 & -0.65 & -0.41 & 0.58 & 0.09
\end{pmatrix}\\\\
&\times&
\begin{pmatrix}
2.16  &  0  &  0  &  0  &  0  &  0\\\\
0  &  1.59  &  0  &  0  &  0  &  0\\\\
0  &  0  &  1.28  &  0  &  0  &  0\\\\
0  &  0  &  0  &  1.00  &  0  &  0\\\\
0 & 0 & 0 & 0 & 0.39  &  0
\end{pmatrix}\\\\
&\times&
\begin{pmatrix}
-0.75 & -0.29 & -0.28 & 0.00 & 0.53 & 0.00 \\\\
-0.28 & -0.53 & 0.75 & -0.00 & -0.29 & -0.00 \\\\
-0.20 & -0.19 & -0.45 & 0.58 & -0.63 & -0.00 \\\\
-0.45 & 0.63 & 0.20 & -0.00 & -0.19 & -0.58 \\\\
-0.33 & 0.22 & -0.12 & -0.58 & -0.41 & 0.58 \\\\
-0.12 & 0.41 & 0.33 & 0.58 & 0.22 & 0.58
\end{pmatrix} ^T\\\\
&=&
\begin{pmatrix}
-1.10 & 0.06 & -0.21 & 0.04 & -0.59 & 0.62 \\\\
-0.30 & -0.84 & 0.36 & 0.11 & 0.23 & -0.13 \\\\
-0.74 & -1.14 & -0.30 & -0.09 & -0.20 & 0.11 \\\\
-1.07 & 0.04 & -0.59 & -0.98 & -0.28 & -0.69 \\\\
0.04 & -0.02 & 0.62 & -1.01 & -0.69 & -0.32
\end{pmatrix}
\end{eqnarray}$$

取$k=2$，此时左奇异向量为

$$\begin{eqnarray}
U_{5\times 2}=\begin{pmatrix}
0.44 & 0.30 \\\\
0.13 & 0.33\\\\
0.48 & 0.51\\\\
0.70 & -0.35\\\\
0.26 & -0.65
\end{pmatrix}
\end{eqnarray}$$

因为$0.44 \gt 0.30$，这表示第一个词与第一维空间更接近，依次类推。

右奇异矩阵为：

$$\begin{eqnarray}
U^T_{2\times 6}=\begin{pmatrix}
-0.75 & -0.28 & -0.20 & -0.45 & -0.33 & -0.12 \\\\
-0.29 & -0.53 & -0.19 & 0.63 & 0.22 & 0.41
\end{pmatrix}
\end{eqnarray}$$

第一列表示文章$d_1$与第一维空间更接近，在些基础上可利用余弦相似度对两篇文档在低维空间上进行相似度计算。

中间矩阵为：

$$\begin{eqnarray}
\Sigma = \begin{pmatrix}
2.16 & 0.00 \\\\
0.00 & 1.59
\end{pmatrix}
\end{eqnarray}$$

表示的是词和文章的相关关系。


# 参考文献

>[奇异值分解 SVD](/2017/04/12/%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3-SVD/)
>[矩阵分解及隐性语义索引](https://liqiangguo.files.wordpress.com/2011/06/lsi.pdf)
>[《数学之美》拾遗——潜在语义索引(LSI)](http://blog.csdn.net/google19890102/article/details/29591553)
